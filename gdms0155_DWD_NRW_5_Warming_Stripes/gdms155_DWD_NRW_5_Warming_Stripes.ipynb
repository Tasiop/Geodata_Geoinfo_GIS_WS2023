{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a981281",
   "metadata": {},
   "source": [
    "## 1. About the DWD Open Data Portal \n",
    "\n",
    "The data of the Climate Data Center (CDC) of the DWD (Deutscher Wetterdienst, German Weather Service) is provided on an **FTP server**. <br> **FTP** stands for _File Transfer Protocol_.\n",
    "\n",
    "Open the FTP link ftp://opendata.dwd.de/climate_environment/CDC/ in your browser (copy-paste) and find our how it is structured hierarchically.\n",
    "\n",
    "You can also open the link with **HTTPS** (Hypertext Transfer Protocol Secure): https://opendata.dwd.de/climate_environment/CDC/\n",
    "\n",
    "We are interested in downloading the metadata of annual temperature to get information related to their stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237f7b7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re # to use regex expressions \n",
    "import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the DWD website\n",
    "url_base = \"https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/\"\n",
    "url_temporal_resolution = \"annual/\"\n",
    "url_parameter = \"kl/\"\n",
    "url_subdir = \"historical/\"\n",
    "url_full = os.path.join(url_base, url_temporal_resolution, url_parameter, url_subdir)\n",
    "\n",
    "# Directory to save the downloaded files\n",
    "download_dir = \"../data/original/dwd/\" +  url_temporal_resolution + url_parameter + url_subdir\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(download_dir):\n",
    "    os.makedirs(download_dir)\n",
    "\n",
    "print(\"download dir: \", download_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaaf11d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url_full"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": null,
   "id": "38652e02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def grab_file(file_url, download_dir):\n",
    "        # get only the file name from the full url\n",
    "        file_name = file_url.split(\"/\")[-1]\n",
    "        # Download the file\n",
    "        file_path =os.path.join(download_dir, file_name)\n",
    "        with open(file_path, \"wb\") as file:\n",
    "            file.write(requests.get(file_url).content)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f495e38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Send an HTTP request to the URL\n",
    "response = requests.get(url_full)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    # Look for the metadata file\n",
    "    links = soup.find_all(href=re.compile(\"Beschreibung\"))\n",
    "    # Take the url of the file\n",
    "    file_name = links[0].get(\"href\")\n",
    "    # Download the file\n",
    "    grab_file(os.path.join(url_full, file_name), download_dir)\n",
    "    print(f\"Downloaded: {download_dir+file_name}\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": null,
   "id": "05b9c788",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get station path\n",
    "file_path = os.path.join(download_dir,file_name)\n",
    "# read the header of the file\n",
    "header = open(file_path, encoding=\"latin\").readline().split()\n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1926c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# translation dictionary\n",
    "translate = \\\n",
    "{'Stations_id':'station_id',\n",
    " 'von_datum':'date_from',\n",
    " 'bis_datum':'date_to',\n",
    " 'Stationshoehe':'altitude',\n",
    " 'geoBreite': 'latitude',\n",
    " 'geoLaenge': 'longitude',\n",
    " 'Stationsname':'name',\n",
    " 'Bundesland':'state'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6b45e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pd.read_csv?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf36e22",
   "metadata": {},
   "source": [
    "# Exercise:\n",
    "notice that stations_id is originally a string, however if you read the data as the default format you will lose the leading zeros from the code.\n",
    "- Check the documentation of pd.read_csv.\n",
    "- Figure out how to correctly read the data. Focus on:\n",
    "    - skiprows\n",
    "    - names\n",
    "    - encoding\n",
    "    - parse_dates\n",
    "    - dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86641b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations_2 = pd.read_fwf(file_path,\n",
    "                          skiprows=[0,1],\n",
    "                          names=translate,\n",
    "                          encoding=\"latin\", \n",
    "                          parse_dates=[\"von_datum\",\"bis_datum\"],\n",
    "                          dtype={\"Stations_id\":str}\n",
    "                          #index_col=\"Stations_id\"\n",
    "                         )\n",
    "df_stations_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ddb057",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read the stations dataframe # solution is in the cell\n",
    "\n",
    "df_stations = pd.read_fwf(file_path,\n",
    "                          skiprows=2,\n",
    "                          names=header,\n",
    "                          encoding=\"latin\", \n",
    "                          parse_dates=[\"von_datum\",\"bis_datum\"],\n",
    "                          dtype={\"Stations_id\":str}\n",
    "                          #index_col=\"Stations_id\"\n",
    "                         )\n",
    "df_stations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f048244",
   "metadata": {},
   "source": [
    "# Exercise:\n",
    "Check all the different values in the \"state\" column. You can use the function <code>.unique()</code> for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b578c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations.rename(columns=translate,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfbe960",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_stations.loc[:,\"state\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c127c1",
   "metadata": {},
   "source": [
    "# Exercise:\n",
    "Select only stations in NRW (you know how it is spelled from the previous exercise) which are still active (date_to is later than 2022) and which starting recording information at least in 1950.\n",
    "**Hint:** On Pandas documentation, look for Dataframe.query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c109d8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_stations.query?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffbd795",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filter stations only in NRW which are active and older than 1950\n",
    "df_stations_short = df_stations.query(\"state == 'Nordrhein-Westfalen' and date_to >= 2022 and date_from <= 1950\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10ace5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_stations.query?    REALLY USE THE ???? AND LOOK CLOSELY AT THE EXAPLES IN THERE\n",
    "\n",
    "df_stations_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc01d48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the links. \n",
    "links = soup.find_all(href=[re.compile(\"KL_\"+x) for x in df_stations_short.loc[:,\"station_id\"]])\n",
    "links\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45017f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4add166e",
   "metadata": {},
   "source": [
    "# Question:\n",
    "1) how does re.compile works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fbaf86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # iterate through the list\n",
    "    for link in tqdm.tqdm(links):\n",
    "        # Take the url of the file\n",
    "        file_name = link.get(\"href\")\n",
    "        # Download the file\n",
    "        grab_file(os.path.join(url_full, file_name), download_dir)\n",
    "    \n",
    "except:\n",
    "    print(\"Failed to download\")\n",
    "\n",
    "print(\"Download complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f0afd3",
   "metadata": {},
   "source": [
    "### Which file do I need?\n",
    "extract one of the zip files to look at the content. Identify which file contains the data you are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f615b39a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "zip_list = glob.glob(download_dir+\"*.zip\")\n",
    "zip_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c69988d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "# example of the files inside the first zip file\n",
    "with ZipFile(zip_list[0]) as myzip:\n",
    "    print(myzip.namelist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea264c8",
   "metadata": {},
   "source": [
    "# Question\n",
    "Inspect the different files from the archive (.zip) example. \n",
    "1. Which file contains the temperature data? \n",
    "1. Which other parameters can be found inside?\n",
    "\n",
    "You can find below the file names translated.\n",
    "- 'Metadaten_Stationsname_Betreibername': Metadata stations' name and operator's name  \n",
    "- 'Metadaten_Parameter_klima_jahr': Metadata parameters climate year\n",
    "- 'Metadaten_Geraete_Lufttemperatur': Metadata devices air temperature\n",
    "- 'Metadaten_Geraete_Lufttemperatur_Maximum': Metadata devices air temperature maximum\n",
    "- 'Metadaten_Geraete_Lufttemperatur_Minimum': Metadata devices air temperature minimum\n",
    "- 'Metadaten_Geraete_Niederschlagshoehe': Metadata devices precipitation height\n",
    "- 'Metadaten_Geraete_Sonnenscheindauer': Metadata devices sunshine time\n",
    "- 'Metadaten_Fehldaten': Metadata missing data\n",
    "- 'Metadaten_Fehlwerte': Metadata Errors\n",
    "- 'produkt_klima_jahr': Product climate year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2512ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use the name pattern to get the file name\n",
    "with ZipFile(zip_list[0]) as myzip:\n",
    "    prod_filename = [name for name in myzip.namelist() if name.split(\"_\")[0]==\"produkt\"][0] \n",
    "    print(prod_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0883ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read one of the files as examplez\n",
    "\n",
    "with ZipFile(zip_list[0]) as myzip:\n",
    "    prod_filename = [name for name in myzip.namelist() if name.split(\"_\")[0]==\"produkt\"][0] \n",
    "    \n",
    "    #open just the product file within archive\n",
    "    with myzip.open(prod_filename) as myfile:\n",
    "    # read the time series data in a temporal dataframe\n",
    "        df_temp = pd.read_csv(myfile, \n",
    "                      sep=\";\", \n",
    "                      parse_dates = [\"MESS_DATUM_BEGINN\", \"MESS_DATUM_ENDE\"], \n",
    "                      index_col = \"MESS_DATUM_BEGINN\", \n",
    "                      na_values = [-999.0],\n",
    "                    dtype={'STATIONS_ID':str}\n",
    "                         )\n",
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e375b7",
   "metadata": {},
   "source": [
    "Now repeat the example with all the files in the ziplist. And join them in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59865167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create an empty dataFrame to merge the temperature data to\n",
    "df_temp = pd.DataFrame()\n",
    "# iterate through the zipfiles\n",
    "for zip_file in zip_list:\n",
    "    with ZipFile(zip_file) as myzip:\n",
    "        #we are only interested in the file starting with 'produkt_'\n",
    "        prod_filename = [name for name in myzip.namelist() if name.split(\"_\")[0]==\"produkt\"][0] \n",
    "        \n",
    "        #open just the product file within archive\n",
    "        with myzip.open(prod_filename) as myfile:\n",
    "            # read the time series data in a temporal dataframe\n",
    "            df_dummy = pd.read_csv(myfile, \n",
    "                                  sep=\";\", \n",
    "                                  parse_dates = [\"MESS_DATUM_BEGINN\", \"MESS_DATUM_ENDE\"], \n",
    "                                  index_col = \"MESS_DATUM_BEGINN\", \n",
    "                                  na_values = [-999.0],\n",
    "                                  dtype={\"STATIONS_ID\":str}\n",
    "                                 )\n",
    "            # Only interested in the average temperature parameter\n",
    "            temp_series = df_dummy[\"JA_TT\"].rename(df_dummy[\"STATIONS_ID\"].iloc[0]).to_frame()\n",
    "            # outer join\n",
    "            df_temp = pd.merge(df_temp,temp_series,left_index=True, right_index=True, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54a8b89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fc785a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_temp.index.rename(name='year', inplace=True)\n",
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ffd4d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace full datetime with year as integer\n",
    "try:\n",
    "    df_temp.set_index(df_temp.index.year, inplace= True) # extract year from index as int\n",
    "except:\n",
    "    next\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a72b38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean = df_temp[(df_temp.index >= 1961) & (df_temp.index <= 1990)].mean() # mean annual temp between 1961 and 1990\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531880a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_temp_diff = (df_temp - mean)\n",
    "df_temp_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525281b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_temp_diff.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111c63b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot\n",
    "sns.set_style('ticks')\n",
    "fig1, ax1 = plt.subplots(dpi = 300, figsize = (30,10))\n",
    "\n",
    "sns.heatmap(df_temp.T, cmap='coolwarm', ax = ax1)\n",
    "fig1.savefig('NRW_Annual_Temp_Stripes_01.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ed0f0e",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "The resolution of the plot above is not optimal. Only one station started getting data from 1851. Remember that you applied a filter to the list of the stations, so it makes sense to only display data within that window of dates.\n",
    "1) generate a new plot displaying only the measurements from 1950"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb40c3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b57c13",
   "metadata": {},
   "source": [
    "# Exercise:\n",
    "Good! now have a look at the temperature values. Some stations have very cool temperatures all over the series. We can assume that it is an effect of the geographic location, maybe the colder stations are placed at higher altitudes. You can investigate that by looking at your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67375ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_stations_short.filter(like=\"Stations\")  #like se usa para todas las cosas que tengan =() en sus palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf26e33",
   "metadata": {},
   "source": [
    "We are actually interested at the changes in temperature relative to the mean historical measurements.\n",
    "By plotting the temperatures differences a blue tone means a measurement below the average of that stations and a red tone means that the measurement was above the average of the station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d17e272",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \n",
    "sns.set_style('ticks')\n",
    "fig3, ax3 = plt.subplots(dpi = 150, figsize = (12,4))\n",
    "\n",
    "sns.heatmap(df_temp_diff[df_temp_diff.index >= 1950].T, cmap='coolwarm', vmin = -2, vmax = 2, ax = ax3)\n",
    "fig3.savefig('NRW_Annual_Temp_Diff_Stripes_02.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb093a0",
   "metadata": {},
   "source": [
    "# Question:\n",
    "\n",
    "- Which tendency can you see in the temperature according the plot above?\n",
    "- Why does station 555 display a different tendency than the other stations?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
